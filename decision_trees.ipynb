{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "You will be implementing and evaluating a Decision Tree using the ID3 Algorithm (**no** pruning or normalized information gain). Use the provided pseudocode. The data is located at (copy link):\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "**Just in case** the UCI repository is down, which happens from time to time, I have included the data and name files on Blackboard.\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Important</strong>\n",
    "    <p>\n",
    "        No Pandas. The only acceptable libraries in this class are those contained in the `environment.yml`. No OOP, either. You can used Dicts, NamedTuples, etc. as your abstract data type (ADT) for the the tree and nodes.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "One of the things we did not talk about in the lectures was how to deal with missing values. There are two aspects of the problem here. What do we do with missing values in the training data? What do we do with missing values when doing classifcation?\n",
    "\n",
    "For the first problem, C4.5 handled missing values in an interesting way. Suppose we have identifed some attribute *B* with values {b1, b2, b3} as the best current attribute. Furthermore, assume there are 5 observations with B=?, that is, we don't know the attribute value. In C4.5, those 5 observations would be added to *all* of the subsets created by B=b1, B=b2, B=b3 with decreased weights. Note that the observations with missing values are not part of the information gain calculation.\n",
    "\n",
    "This doesn't quite help us if we have missing values when we use the model. What happens if we have missing values during classification? One approach is to prepare for this advance. When you train the tree, you need to add an implicit attribute value \"?\" at every split. For example, if the attribute was \"size\" then the domain would be [\"small\", \"medium\", \"large\", \"?\"]. The \"?\" value gets all the data (because ? is now a wildcard). However, there is an issue with this approach. \"?\" becomes the worst possible attribut value because it has no classification value. What to do? There are several options:\n",
    "\n",
    "1. Never recurse on \"?\" if you do not also recurse on at least one *real* attribute value.\n",
    "2. Limit the depth of the tree.\n",
    "\n",
    "There are good reasons, in general, to limit the depth of a decision tree because they tend to overfit.\n",
    "Otherwise, the algorithm *will* exhaust all the attributes trying to fulfill one of the base cases.\n",
    "\n",
    "You must implement the following functions:\n",
    "\n",
    "`train` takes training_data and returns the Decision Tree as a data structure. There are many options including namedtuples and just plain old nested dictionaries. **No OOP**.\n",
    "\n",
    "```\n",
    "def train(training_data, depth_limit=None):\n",
    "   # returns the Decision Tree.\n",
    "```\n",
    "\n",
    "The `depth_limit` value defaults to None. (What technique would we use to determine the best parameter value for `depth_limit` hint: Module 3!)\n",
    "\n",
    "`classify` takes a tree produced from the function above and applies it to labeled data (like the test set) or unlabeled data (like some new data).\n",
    "\n",
    "```\n",
    "def classify(tree, observations, labeled=True):\n",
    "    # returns a list of classifications\n",
    "```\n",
    "\n",
    "`evaluate` takes a data set with labels (like the training set or test set) and the classification result and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "Do not use anything else as evaluation metric or the submission will be deemed incomplete, ie, an \"F\". (Hint: accuracy rate is not the error rate!).\n",
    "\n",
    "`cross_validate` takes the data and uses 10 fold cross validation (from Module 3!) to `train`, `classify`, and `evaluate`. **Remember to shuffle your data before you create your folds**. I leave the exact signature of `cross_validate` to you but you should write it so that you can use it with *any* `classify` function of the same form (using higher order functions and partial application).\n",
    "\n",
    "Following Module 3's discussion, `cross_validate` should print out the fold number and the evaluation metric (error rate) for each fold and then the average value (and the variance). What you are looking for here is a consistent evaluation metric cross the folds. You should print the error rates in terms of percents (ie, multiply the error rate by 100 and add \"%\" to the end).\n",
    "\n",
    "```\n",
    "def pretty_print_tree(tree):\n",
    "    # pretty prints the tree\n",
    "```\n",
    "\n",
    "This should be a text representation of a decision tree trained on the entire data set (no train/test).\n",
    "\n",
    "To summarize...\n",
    "\n",
    "Apply the Decision Tree algorithm to the Mushroom data set using 10 fold cross validation and the error rate as the evaluation metric. When you are done, apply the Decision Tree algorithm to the entire data set and print out the resulting tree.\n",
    "\n",
    "**Note** Because this assignment has a natural recursive implementation, you should consider using `deepcopy` at the appropriate places.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [str(value) for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data(\"data/agaricus-lepiota.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8124"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises?\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"population\",\n",
    "    \"habitat\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"extract_column\"></a>\n",
    "### extract_column\n",
    "\n",
    "`extract_column` extracts a column into a list from a list of lists. **Used by**: \n",
    "\n",
    "* **data** List[List]: the list of lists\n",
    "* **column** int: determines which column to extract\n",
    "\n",
    "**return**: List: the extracted column as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_column(data: List[List], column) -> List:\n",
    "    extract = []\n",
    "    for i, value in enumerate(data):\n",
    "        extract.append(data[i][column])\n",
    "    return extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    return list(xs[i * k + min(i, m) : (i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(\n",
    "    folds: List[List[List]], index: int\n",
    ") -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id3\"></a>\n",
    "### id3\n",
    "\n",
    "`id3` runs the id3 algorithm to build a decision tree. **Uses**: \n",
    "\n",
    "* **data** List[List]: the list cantaining the data\n",
    "* **attributes** List: identifies the attributes in the data\n",
    "\n",
    "**return**: List: the extracted column as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, attributes, default) -> Dict:\n",
    "    if len(data) == 0:\n",
    "        return default\n",
    "    h = is_homogenous(data)\n",
    "    if h is not None:\n",
    "        return h\n",
    "    if attributes == []:\n",
    "        label = majority_label(data)\n",
    "        return label\n",
    "    best_attr = pick_best_attribute(data, attributes)\n",
    "    attr = best_attr[0]\n",
    "    attr_index = attributes.index(best_attr[0]) + 1\n",
    "    domain = np.unique(extract_column(data, attr_index))\n",
    "    np.append(domain, \"?\")\n",
    "    node = new_node(attr, domain)\n",
    "    default_value = majority_label(data)\n",
    "\n",
    "    for value in domain:\n",
    "        subset = attr_value(data, value, attr_index)\n",
    "        _attributes = deepcopy(attributes)\n",
    "        del _attributes[attr_index - 1]\n",
    "        child = id3(subset, _attributes, default_value)\n",
    "        node[attr][value] = child\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"attr_value\"></a>\n",
    "### attr_value\n",
    "\n",
    "`attr_value` creates a subset of data for the recursive calls. **Used by**: \n",
    "\n",
    "* **data** List[List]: the list cantaining the data\n",
    "* **value** List: identifies which value is being used for the subset\n",
    "\n",
    "**return**: List: subset as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_value(data, value, attr_index):\n",
    "    subset = []\n",
    "    if value == \"?\":\n",
    "        for i in data:\n",
    "            subset.append(i[:attr_index] + i[attr_index + 1 :])\n",
    "        return subset\n",
    "    for i in data:\n",
    "        if i[attr_index] == value:\n",
    "            subset.append(i[:attr_index] + i[attr_index + 1 :])\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"new_node\"></a>\n",
    "### new_node\n",
    "\n",
    "`new_node` creates a node for the tree. **Used by**: \n",
    "\n",
    "* **attribute** str: the attribute of interest\n",
    "* **domain** List: the unique values in the desired attribute\n",
    "\n",
    "**return**: Dict: dictionary containing the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_node(attribute, domain):\n",
    "    for i in domain:\n",
    "        tree = {attribute: {i: None}}\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"is_homogenous\"></a>\n",
    "### is_homogenous\n",
    "\n",
    "`is_homogenous` determines if an attribute is homogenous. **Used by**: \n",
    "\n",
    "* **data** List[List]: the list cantaining the data\n",
    "\n",
    "**return**: str: returns the class label if homogenous or none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_homogenous(data):\n",
    "    col = extract_column(data, 0)\n",
    "    if col.count(\"e\") == len(data):\n",
    "        return \"e\"\n",
    "    if col.count(\"p\") == len(data):\n",
    "        return \"p\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"majority_label\"></a>\n",
    "### majority_label\n",
    "\n",
    "`majority_label` determines the majority class label. **Used by**: \n",
    "\n",
    "* **data** List[List]: the list cantaining the data\n",
    "\n",
    "**return**: str: returns the class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_label(data):\n",
    "    col = extract_column(data, 0)\n",
    "    if col.count(\"e\") > col.count(\"p\"):\n",
    "        majority = \"e\"\n",
    "    else:\n",
    "        majority = \"p\"\n",
    "    return majority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pick_best_attribute\"></a>\n",
    "### pick_best_attribute\n",
    "\n",
    "`pick_best_attribute` determines the attribute with the most gain. **Used by**: \n",
    "\n",
    "* **data** List[List]: the list cantaining the data\n",
    "* **attributes** List: list of attributes\n",
    "\n",
    "**return**: List: returns the attribute with the most gain and the gain value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_attribute(data, attributes) -> List:\n",
    "    col_class = extract_column(data, 0)\n",
    "    e_total = entropy(col_class)\n",
    "    a_dict = create_attribute_dict(data, attributes)\n",
    "    e_dict = entropy_dict(a_dict)\n",
    "    i_dict = information_gain(e_dict, e_total, data)\n",
    "    max_gain = (0, 0)\n",
    "    for key in i_dict:\n",
    "        if i_dict[key][\"gain\"] > max_gain[1]:\n",
    "            max_gain = (key, i_dict[key][\"gain\"])\n",
    "    return max_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_attribute_dict\"></a>\n",
    "### create_attribute_dict\n",
    "\n",
    "`create_attribute_dict` creates a dictionary from the attributes to count the class labels for each attribute. **Used by**: \n",
    "\n",
    "* **data** List[List]: the list cantaining the data\n",
    "* **attributes** List: list of attributes\n",
    "\n",
    "**return**: Dict: returns a dictionary of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attribute_dict(data, attributes) -> Dict:\n",
    "    a_dict = {}\n",
    "    for i, a in enumerate(attributes):\n",
    "        a_dict[a] = {}\n",
    "        col = extract_column(data, i + 1)\n",
    "        unique = np.unique(col)\n",
    "        for u in unique:\n",
    "            a_dict[a][u] = {\"p\": 0, \"e\": 0}\n",
    "            for d in data:\n",
    "                if d[i + 1] == u:\n",
    "                    if d[0] == \"p\":\n",
    "                        a_dict[a][u][\"p\"] += 1\n",
    "                    if d[0] == \"e\":\n",
    "                        a_dict[a][u][\"e\"] += 1\n",
    "    return a_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"entropy\"></a>\n",
    "### entropy\n",
    "\n",
    "`entropy` Calculates the entropy of a list of values **Used by**: [pick_best_attribute](#pick_best_attribute)\n",
    "\n",
    "* **data** List[List]: the list values to calculate entropy from\n",
    "\n",
    "**return**: Float: the resulting entropy number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data: List) -> float:\n",
    "    p = []\n",
    "    e = 0\n",
    "    d = np.unique(data)\n",
    "    for i, v in enumerate(d):\n",
    "        c = data.count(v) / len(data)\n",
    "        p.append(c)\n",
    "    for i in p:\n",
    "        e += i * (np.log2(i))\n",
    "    return abs(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_dict(_a_dict):\n",
    "    a_dict = deepcopy(_a_dict)\n",
    "    for key in a_dict:\n",
    "        for key2 in a_dict[key]:\n",
    "            t_e = a_dict[key][key2][\"e\"]\n",
    "            t_p = a_dict[key][key2][\"p\"]\n",
    "            t = t_p + t_e\n",
    "            if t_e == t or t_p == t:\n",
    "                a_dict[key][key2][\"entropy\"] = 0\n",
    "            else:\n",
    "                entr = abs((t_p / t) * np.log2(t_p / t) + (t_e / t) * np.log2(t_e / t))\n",
    "                a_dict[key][key2][\"entropy\"] = entr\n",
    "    return a_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(_a_dict, e_total, data):\n",
    "    a_dict = deepcopy(_a_dict)\n",
    "    s = len(data)\n",
    "    for key in a_dict:\n",
    "        g_partial = 0\n",
    "        for key2 in a_dict[key]:\n",
    "            t_e = a_dict[key][key2][\"e\"]\n",
    "            t_p = a_dict[key][key2][\"p\"]\n",
    "            t = t_p + t_e\n",
    "            g_partial += (t / s) * a_dict[key][key2][\"entropy\"]\n",
    "        g = e_total - g_partial\n",
    "        a_dict[key][\"gain\"] = g\n",
    "    return a_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, attributes, depth_limit=None) -> Dict:\n",
    "    model = id3(training_data, attributes, \"e\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tries to classify data using tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, attributes, observations, labeled=True) -> List:\n",
    "    result = []\n",
    "    attr_index = []\n",
    "    list_keys = []\n",
    "    classification = []\n",
    "    for x in get_keys(tree):\n",
    "        list_keys.append(x)\n",
    "    for point in observations:\n",
    "        for i in list_keys:\n",
    "            if i in attributes:\n",
    "                attr_index = attributes.index(i) + 1\n",
    "                classification.append((i, point[attr_index]))\n",
    "        value = tree[\"odor\"]\n",
    "        for a in classification:\n",
    "            if a[0] in attributes:\n",
    "                if isinstance(value[a[1]], dict):\n",
    "                    value = value[a[1]]\n",
    "                    k_list = list(value)\n",
    "                    value = value[k_list[0]]\n",
    "                else:\n",
    "                    value = value[a[1]]\n",
    "                    break\n",
    "        result.append(value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(dictionary):\n",
    "    for key, value in dictionary.items():\n",
    "        yield key\n",
    "        if isinstance(value, dict):\n",
    "            yield from get_keys(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification error rate: errors/number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_set, classification_result) -> float:\n",
    "    correct = 0\n",
    "    actual = extract_column(data_set, 0)\n",
    "    for i, value in enumerate(actual):\n",
    "        if classification_result[i] == actual[i]:\n",
    "            correct += 1\n",
    "    result = correct / len(actual)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation (train, classify, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(data, attributes, classify_function, eval_function) -> Any:\n",
    "    folds = create_folds(data, 10)\n",
    "    for i, fold in enumerate(folds):\n",
    "        train_data, test = create_train_test(folds, i)\n",
    "        model = train(train_data, attributes, None)\n",
    "        clf = classify_function(model, attributes, test)\n",
    "        eval_clf = eval_function(test, clf)\n",
    "        print(f\"Fold {i+1} error rate {eval_clf}\")\n",
    "    return eval_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 error rate 0.45264452644526443\n",
      "Fold 2 error rate 0.5079950799507995\n",
      "Fold 3 error rate 0.4858548585485855\n",
      "Fold 4 error rate 0.5043050430504306\n",
      "Fold 5 error rate 0.5147783251231527\n",
      "Fold 6 error rate 0.46798029556650245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 error rate 0.47167487684729065\n",
      "Fold 8 error rate 0.4876847290640394\n",
      "Fold 9 error rate 0.4827586206896552\n",
      "Fold 10 error rate 0.5012315270935961\n"
     ]
    }
   ],
   "source": [
    "model = cross_validate(data, attributes, classify, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'odor': {'a': 'e',\n",
      "          'c': 'p',\n",
      "          'f': 'p',\n",
      "          'l': 'e',\n",
      "          'm': 'p',\n",
      "          'n': {'spore-print-color': {'b': 'e',\n",
      "                                      'h': 'e',\n",
      "                                      'k': 'e',\n",
      "                                      'n': 'e',\n",
      "                                      'o': 'e',\n",
      "                                      'r': 'p',\n",
      "                                      'w': {'habitat': {'d': {'gill-size': {'b': 'e',\n",
      "                                                                            'n': 'p'}},\n",
      "                                                        'g': 'e',\n",
      "                                                        'l': {'cap-color': {'c': 'e',\n",
      "                                                                            'n': 'e',\n",
      "                                                                            'w': 'p',\n",
      "                                                                            'y': 'p'}},\n",
      "                                                        'p': 'e',\n",
      "                                                        'w': 'e'}},\n",
      "                                      'y': 'e'}},\n",
      "          'p': 'p',\n",
      "          's': 'p',\n",
      "          'y': 'p'}}\n"
     ]
    }
   ],
   "source": [
    "b = id3(data, attributes, \"e\")\n",
    "pprint(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
